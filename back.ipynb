{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-02T19:47:43.529797Z",
     "start_time": "2025-05-02T19:47:43.307629Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import ast\n",
    "#import fitz \n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:47:45.479517Z",
     "start_time": "2025-05-02T19:47:45.443853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"princeton-nlp/sup-simcse-roberta-base\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "MAX_LENGTH = 256"
   ],
   "id": "c2d134862b0380a9",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model load",
   "id": "371bfc70cbdc234b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:47:48.361528Z",
     "start_time": "2025-05-02T19:47:48.312636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SiameseSimCSE(nn.Module):\n",
    "    def __init__(self, model_name, freeze_percentage=0.8):\n",
    "        super(SiameseSimCSE, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        total_layers = len(self.encoder.encoder.layer)\n",
    "        layers_to_freeze = int(total_layers * freeze_percentage)\n",
    "\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False  \n",
    "\n",
    "        for i in range(layers_to_freeze, total_layers):\n",
    "            for param in self.encoder.encoder.layer[i].parameters():\n",
    "                param.requires_grad = True  \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = output.last_hidden_state[:, 0] \n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)  \n",
    "        return embeddings"
   ],
   "id": "8a03fe680d53d6d",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:48:04.620949Z",
     "start_time": "2025-05-02T19:47:48.712995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_load = SiameseSimCSE(MODEL_NAME).to(device)\n",
    "model_load.load_state_dict(torch.load(\"mse_base.pth\", map_location=torch.device(\"cpu\")))\n",
    "model_load.to(device)\n",
    "model_load.eval()"
   ],
   "id": "b1d5e9d5681a8418",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SiameseSimCSE(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 165
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preproc for model",
   "id": "768465d0e8bdd036"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:48:07.448143Z",
     "start_time": "2025-05-02T19:48:04.738947Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)",
   "id": "521fe4985a9e9982",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:48:07.525499Z",
     "start_time": "2025-05-02T19:48:07.453775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '<url>', text)\n",
    "    emoji_pattern = re.compile(\"[\"  \n",
    "                                u\"\\U0001F600-\\U0001F64F\"   # Emoji: Emoticons\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"   # Emoji: Miscellaneous Symbols and Pictographs\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"   # Emoji: Transport and Map Symbols\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"   # Emoji: Regional Indicator Symbols\n",
    "                                u\"\\U00002500-\\U00002BEF\"   # Emoji: CJK Ideograph Extension A\n",
    "                                u\"\\U00002702-\\U000027B0\"   # Emoji: Dingbats\n",
    "                                u\"\\U000024C2-\\U0001F251\"   # Emoji: Enclosed Characters\n",
    "                                u\"\\U0001F926-\\U0001F937\"   # Emoji: People\n",
    "                                u\"\\U00010000-\\U0010FFFF\"   # Emoji: Supplemental Multilingual Plane\n",
    "                                u\"\\u200d\"                   # Zero Width Joiner\n",
    "                                u\"\\u2640-\\u2642\"            # Emoji: Gender Symbols\n",
    "                                u\"\\u2600-\\u2B55\"            # Emoji: Miscellaneous Symbols\n",
    "                                u\"\\u23cf\\u23e9\\u231a\"      # Emoji: Miscellaneous symbols\n",
    "                                u\"\\u3030\"                   # Emoji: Japanese Characters\n",
    "                                u\"\\ufe0f\\u2069\\u2066\"      # Emoji: Variation Selectors\n",
    "                                u\"\\u200c\\u2068\\u2067\"      # Emoji: Zero Width Non-Joiner\n",
    "                                \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    text = re.sub(r'[\\xa0\\u200d\\t\\r\\n]+', ' ', text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "    text = re.sub(r\"[^\\w\\s\\.,'!?]\", '', text)\n",
    "\n",
    "    return text\n"
   ],
   "id": "c66e047e3e9d3741",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Connection with DB",
   "id": "42dba0e2eadc322d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:48:11.739153Z",
     "start_time": "2025-05-02T19:48:11.670678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VectorDB:\n",
    "    def __init__(self, dbname=\"vectordb\", user=\"admin\", password=\"admin\", host=\"localhost\", port=5432):\n",
    "        self.connection = psycopg2.connect(\n",
    "            dbname=dbname, user=user, password=password, host=host, port=port\n",
    "        )\n",
    "\n",
    "    def load_candidates(self, df):\n",
    "        cur = self.connection.cursor()\n",
    "        for _, row in df.iterrows():\n",
    "            cur.execute(\n",
    "                \"INSERT INTO candidates (resume_text, embedding_vector) VALUES (%s, %s)\",\n",
    "                (row['resume_text'], row['resume_embeddings'])\n",
    "            )\n",
    "        self.connection.commit()\n",
    "        cur.close()\n",
    "        return f\"{len(df)} records saved to candidates table.\"\n",
    "\n",
    "    def save_feedback(self, df):\n",
    "        cur = self.connection.cursor()\n",
    "        for _, row in df.iterrows():\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO feedback (job_description_text, resume_text, label)\n",
    "                VALUES (%s, %s, %s)\n",
    "                \"\"\",\n",
    "                (row[\"vacancy\"], row[\"candidate\"], row[\"label\"])\n",
    "            )\n",
    "        self.connection.commit()\n",
    "        cur.close()\n",
    "        return f\"{len(df)} records saved to feedback table.\"\n",
    "\n",
    "    def insert_vacancy(self, vacancy_text, vacancy_embedding, vacancy_link=None):\n",
    "        cur = self.connection.cursor()\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO vacancies (vacancy_text, vacancy_link, embedding_vector)\n",
    "            VALUES (%s, %s, %s)\n",
    "            RETURNING vacancy_id\n",
    "            \"\"\",\n",
    "            (vacancy_text, vacancy_link, vacancy_embedding)\n",
    "        )\n",
    "        vacancy_id = cur.fetchone()[0]\n",
    "        self.connection.commit()\n",
    "        cur.close()\n",
    "        return vacancy_id\n",
    "\n",
    "    def find_similar_candidates(self, k, vacancy_id):\n",
    "        cur = self.connection.cursor()\n",
    "        cur.execute(\n",
    "            \"SELECT embedding_vector FROM vacancies WHERE vacancy_id = %s\",\n",
    "            (vacancy_id,)\n",
    "        )\n",
    "        result = cur.fetchone()\n",
    "        if not result:\n",
    "            cur.close()\n",
    "            return \"Vacancy not found\"\n",
    "        \n",
    "        vacancy_embedding = result[0]\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT (1 - (embedding_vector <=> %s)) AS similarity, resume_text\n",
    "            FROM candidates\n",
    "            ORDER BY similarity DESC\n",
    "            LIMIT %s\n",
    "            \"\"\",\n",
    "            (vacancy_embedding, k)\n",
    "        )\n",
    "        results = cur.fetchall()\n",
    "        cur.close()\n",
    "        return results\n",
    "\n",
    "    def close(self):\n",
    "        self.connection.close()\n"
   ],
   "id": "f655a6fcb0ae3f30",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text extraction and preproc",
   "id": "be44fed6ef000c0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:48:16.446836Z",
     "start_time": "2025-05-02T19:48:16.400646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        return f\"Error during loading web-page: {str(e)}\"\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\", \"aside\", \"form\", \"noscript\"]):\n",
    "        tag.decompose()\n",
    "    main_content = soup.find(\"main\")\n",
    "    if not main_content:\n",
    "        main_content = max(soup.find_all(\"div\"), key=lambda d: len(d.get_text(strip=True)), default=None)\n",
    "\n",
    "    if main_content:\n",
    "        text = main_content.get_text(separator=' ', strip=True)\n",
    "    else:\n",
    "        text = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "    return text\n"
   ],
   "id": "52f94b08381f6072",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T19:48:32.819821Z",
     "start_time": "2025-05-02T19:48:32.806953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text(input_type, text_input=None, url=None, pdf_file=None):\n",
    "    if input_type == \"from url\":\n",
    "        try:\n",
    "            text = extract_text_from_url(url)\n",
    "        except Exception as e:\n",
    "            return f\"Error fetching URL: {e}\"\n",
    "\n",
    "    # elif input_type == \"from pdf\":\n",
    "    #     try:\n",
    "    #         doc = fitz.open(stream=pdf_file.read(), filetype=\"pdf\")\n",
    "    #         text = \"\"\n",
    "    #         for page in doc:\n",
    "    #             text += page.get_text()\n",
    "    #     except Exception as e:\n",
    "    #         return f\"Error reading PDF: {e}\"\n",
    "\n",
    "    elif input_type == \"from text\":\n",
    "        text = text_input\n",
    "\n",
    "    else:\n",
    "        return \"Invalid input type\"\n",
    "\n",
    "    return text\n"
   ],
   "id": "c5a956c87ff59310",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T20:01:23.497211Z",
     "start_time": "2025-05-02T20:01:23.487311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_embedding(input_type, text_input=None, url=None, pdf_file=None):\n",
    "    \n",
    "    db = VectorDB()\n",
    "    \n",
    "    raw_text = extract_text(input_type, text_input, url, pdf_file)\n",
    "\n",
    "    if not isinstance(raw_text, str):\n",
    "        return raw_text\n",
    "    \n",
    "    cleaned_text = preprocess_text(raw_text)\n",
    "    \n",
    "    encoded = tokenizer(\n",
    "        cleaned_text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = model_load(input_ids, attention_mask)\n",
    "        \n",
    "    url = url if url else ''\n",
    "    \n",
    "    embedding = embedding[0].cpu().numpy().tolist()\n",
    "    vacancy_id = db.insert_vacancy(cleaned_text,embedding, url)\n",
    "    \n",
    "    return cleaned_text, vacancy_id\n"
   ],
   "id": "291d0cd89be5193a",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T13:06:06.690659Z",
     "start_time": "2025-04-29T13:06:06.676678Z"
    }
   },
   "cell_type": "code",
   "source": "link = 'https://jobs.develops.today/jobs/manual-qa-engineer'",
   "id": "74b7ca59853ffaa7",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## API",
   "id": "17c5a40db4a5a784"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T20:01:25.816254Z",
     "start_time": "2025-05-02T20:01:25.805401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stored_candidates = []\n",
    "\n",
    "def interface_submit_vacancy(input_type, text_input, url_input):\n",
    "    cleaned_text, vacancy_id = get_embedding(\n",
    "        input_type=input_type,\n",
    "        text_input=text_input if input_type == \"from text\" else None,\n",
    "        url=url_input if input_type == \"from url\" else None,\n",
    "    )\n",
    "    return cleaned_text, vacancy_id, \"Data has been successfully encoded\"\n",
    "\n",
    "def interface_find_candidates(k, vacancy_id):\n",
    "    k = int(k)\n",
    "    db = VectorDB()\n",
    "    \n",
    "    candidates =db.find_similar_candidates(k, vacancy_id)\n",
    "    results = [(round(sim, 4), text) for sim, text in candidates]\n",
    "    \n",
    "    return results \n",
    "\n",
    "def save_labels(cleaned_text, *values):\n",
    "    \n",
    "    db = VectorDB()\n",
    "    labels = values[:10] \n",
    "    candidates = values[10:]  \n",
    "\n",
    "    data = []\n",
    "    for i in range(10):\n",
    "        if candidates[i].strip():  \n",
    "            data.append({\n",
    "                \"vacancy\": cleaned_text,\n",
    "                \"candidate\": candidates[i],\n",
    "                \"label\": labels[i]\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return db.save_feedback(df)"
   ],
   "id": "544d3515179cc132",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T20:07:08.417035Z",
     "start_time": "2025-05-02T20:06:39.683337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Candidate Matcher\")\n",
    "\n",
    "    input_type = gr.Radio(choices=[\"from url\", \"from text\"], label=\"Input type\", value=\"from text\")\n",
    "\n",
    "    with gr.Row():\n",
    "        text_input = gr.Textbox(label=\"Type/insert vacancy text here\", lines=8, visible=True)\n",
    "        url_input = gr.Textbox(label=\"Insert vacancy URL here\", visible=False)\n",
    "        \n",
    "    generate_btn = gr.Button(\"Get embedding\")\n",
    "    cleaned_text_output = gr.Textbox(label='Cleaned text', lines=8, visible=False)\n",
    "    embedding_output = gr.Textbox(visible=False)\n",
    "    status_output = gr.Textbox(visible=True, interactive=False, label=\"Embedding status\")\n",
    "    vacancy_id_output = gr.Textbox(label=\"Vacancy ID\")\n",
    "\n",
    "    def toggle_inputs(choice):\n",
    "        return (\n",
    "            gr.update(visible=(choice == \"from text\")),\n",
    "            gr.update(visible=(choice == \"from url\")),\n",
    "            gr.update(visible=(choice == \"from url\"))\n",
    "        )\n",
    "\n",
    "    input_type.change(toggle_inputs, inputs=[input_type], outputs=[text_input, url_input, cleaned_text_output])\n",
    "\n",
    "    generate_btn.click(\n",
    "        interface_submit_vacancy,\n",
    "        inputs=[input_type, text_input, url_input],\n",
    "        outputs=[cleaned_text_output, vacancy_id_output, status_output]\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"## Find similar candidates\")\n",
    "    k_input = gr.Number(label=\"Number of top-k candidates\", value=5, precision=0)\n",
    "    find_btn = gr.Button(\"Find Candidates\")\n",
    "\n",
    "    candidate_rows = []\n",
    "    similarity_bars = []\n",
    "    candidate_boxes = []\n",
    "    label_radios = []\n",
    "\n",
    "    for i in range(10):  \n",
    "        with gr.Column(visible=False) as column:\n",
    "            similarity = gr.Slider(minimum=0, maximum=1, step=0.0001, label=f\"Similarity {i+1}\", interactive=False)\n",
    "            text = gr.Textbox(label=f\"Candidate {i+1}\", lines=5, interactive=False)\n",
    "            radio = gr.Radio(choices=[\"Fit\", \"No Fit\"], label=\"Assessment\", value=\"Fit\", interactive=True)\n",
    "            similarity_bars.append(similarity)\n",
    "            candidate_boxes.append(text)\n",
    "            label_radios.append(radio)\n",
    "            candidate_rows.append(column)\n",
    "\n",
    "    def update_candidate_outputs(k, vacancy_id_output):\n",
    "        results = interface_find_candidates(k, vacancy_id_output)\n",
    "        updates = []\n",
    "\n",
    "        for i in range(10):\n",
    "            if i < len(results):\n",
    "                sim, text = results[i]\n",
    "                updates += [\n",
    "                    gr.update(visible=True),  # column\n",
    "                    gr.update(value=sim),     # similarity slider\n",
    "                    gr.update(value=text),    # resume text\n",
    "                    gr.update(value=\"Fit\")    # Fit/No Fit\n",
    "                ]\n",
    "            else:\n",
    "                updates += [\n",
    "                    gr.update(visible=False),\n",
    "                    gr.update(value=0.0),\n",
    "                    gr.update(value=\"\"),\n",
    "                    gr.update(value=\"Fit\")\n",
    "                ]\n",
    "        return updates\n",
    "\n",
    "    find_btn.click(\n",
    "        update_candidate_outputs,\n",
    "        inputs=[k_input, vacancy_id_output],\n",
    "        outputs=sum([[candidate_rows[i], similarity_bars[i], candidate_boxes[i], label_radios[i]] for i in range(10)], [])\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"## Save Fit/No Fit results\")\n",
    "    save_btn = gr.Button(\"Save Feedback\")\n",
    "    saved_results_output = gr.Textbox(label=\"Saved Results Status\", lines=1)\n",
    "\n",
    "\n",
    "    save_btn.click(\n",
    "        save_labels,\n",
    "        inputs=[cleaned_text_output] + label_radios + candidate_boxes,\n",
    "        outputs=saved_results_output\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True)\n"
   ],
   "id": "a2d9a30bc90efb1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 182
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45ffe046c3aa9c7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
